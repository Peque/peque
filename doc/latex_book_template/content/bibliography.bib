@BOOK{kr,
title={The C Programming Language, 2nd Edition},
author={Brian W. Kernighan and Dennis M. Ritchie},
publisher={Prentice Hall},
year={1988},
month={4},
edition={2},
isbn={9780131103627},
url={http://amazon.com/o/ASIN/0131103628/},
totalpages={274},
timestamp={2014.07.02},
}
@BOOK{gitolite,
title={Gitolite Essentials},
author={Sitaram Chamarty},
publisher={Packt Publishing - ebooks Account},
year={2014},
month={March},
isbn={9781783282371},
url={http://amazon.com/o/ASIN/1783282371/},
totalpages={110},
timestamp={2014.07.02},
}
@BOOK{nison01,
title={Japanese Candlestick Charting Techniques, Second Edition},
author={Steve Nison},
publisher={Prentice Hall Press},
year={2001},
month={10},
edition={2},
isbn={9780735201811},
url={http://amazon.com/o/ASIN/0735201811/},
totalpages={299},
timestamp={2014.07.02},
}
@BOOK{bigalow11,
title={Profitable Candlestick Trading: Pinpointing Market Opportunities to Maximize Profits},
author={Stephen W. Bigalow},
publisher={Wiley},
year={2011},
month={March},
edition={2},
isbn={9780470924709},
url={http://amazon.com/o/ASIN/0470924705/},
totalpages={384},
timestamp={2014.07.02},
}
@BOOK{neely90,
title={Mastering Elliott Wave: Presenting the Neely Method: The First Scientific, Objective Approach to Market Forecasting with the Elliott Wave Theory (version 2)},
author={Glenn Neely and Eric Hall},
publisher={Windsor Books},
year={1990},
month={April},
edition={2nd},
isbn={9780930233440},
url={http://amazon.com/o/ASIN/0930233441/},
totalpages={223},
timestamp={2014.07.02},
}
@BOOK{frost05,
title={Elliott Wave Principle: Key To Market Behavior},
author={A.J. Frost and Robert R. Prechter},
publisher={New Classics Library},
year={2005},
edition={10th},
isbn={9780932750754},
url={http://amazon.com/o/ASIN/0932750753/},
totalpages={254},
timestamp={2014.07.02},
}
@BOOK{brown12,
title={Mastering Elliott Wave Principle: Elementary Concepts, Wave Patterns, and Practice Exercises},
author={Constance Brown},
publisher={Bloomberg Press},
year={2012},
month={May},
edition={1},
isbn={9780470923535},
url={http://amazon.com/o/ASIN/0470923539/},
totalpages={143},
timestamp={2014.07.02},
}
@article{DBLP:journals/corr/abs-1003-0358,
  author    = {Dan Claudiu Ciresan and
               Ueli Meier and
               Luca Maria Gambardella and
               J{\"u}rgen Schmidhuber},
  title     = {Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition},
  journal   = {CoRR},
  volume    = {abs/1003.0358},
  year      = {2010},
  ee        = {http://arxiv.org/abs/1003.0358},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}
@INPROCEEDINGS{bergstra+al:2010-scipy,
     author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
      month = jun,
      title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
  booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
       year = {2010},
   location = {Austin, TX},
       note = {Oral Presentation},
   abstract = {Theano is a compiler for mathematical expressions in Python that combines the convenience of NumPy's syntax with the speed of optimized native machine language. The user composes mathematical expressions in a high-level description that mimics NumPy's syntax and semantics, while being statically typed and
functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates
them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. Common machine learning algorithms implemented with Theano are from 1.6x to 7.5x faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the
CPU and between 6.5× and 44× faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design.}
}
@article{DBLP:journals/corr/abs-1202-2745,
  author    = {Dan C. Ciresan and
               Ueli Meier and
               J{\"u}rgen Schmidhuber},
  title     = {Multi-column Deep Neural Networks for Image Classification},
  journal   = {CoRR},
  volume    = {abs/1202.2745},
  year      = {2012},
  ee        = {http://arxiv.org/abs/1202.2745},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}
